{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report,\n",
    "confusion_matrix\n",
    "import time\n",
    "import joblib\n",
    "from sklearn.impute import SimpleImputer # used for handling missing data\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder # used for\n",
    "encoding categorical data\n",
    "from sklearn.model_selection import train_test_split # used for splitting\n",
    "training and testing data\n",
    "from sklearn.preprocessing import StandardScaler # used for feature scaling\n",
    "[ ]\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Memuat file CSV\n",
    "file_path = 'stew chanel 1 partisi plus label - stew chanel 1 partisi\n",
    "plus label.csv.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "# Memisahkan fitur (X) dan label (y)\n",
    "target_column = 'Kelas' # Nama kolom target\n",
    "X = data.drop(target_column, axis=1) # Menghilangkan kolom target dari\n",
    "fitur\n",
    "y = data[target_column] # Hanya kolom target\n",
    "# Memisahkan data menjadi data latih (train data) dan data uji (test\n",
    "data)\n",
    "# test_size menentukan proporsi data uji (biasanya antara 0.2 hingga 0.3)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
    "random_state=42)\n",
    "# Menggabungkan fitur dan label untuk data latih dan data uji\n",
    "train_data = pd.concat([X_train, y_train], axis=1)\n",
    "test_data = pd.concat([X_test, y_test], axis=1)\n",
    "# Menyimpan data latih ke dalam file CSV\n",
    "train_data.to_csv('train_data.csv', index=False)\n",
    "# Menyimpan data uji ke dalam file CSV\n",
    "test_data.to_csv('test_data.csv', index=False)\n",
    "[ ]\n",
    "path = \"train_data.csv\"\n",
    "df_bonus = pd.read_csv(path)\n",
    "[ ]\n",
    "path = \"test_data.csv\"\n",
    "df_test = pd.read_csv(path)\n",
    "[ ]\n",
    "print(\"\\nOriginal file:\")\n",
    "#print(file)\n",
    "# adding header\n",
    "headerList = ['F1', 'F2', 'F3', 'F4', 'F5', 'F6', 'F7', 'F8', 'F9', 'F10', 'F11',\n",
    "'F12', 'F13', 'F14', 'F15', 'F16', 'F17', 'F18', 'F19', 'F20', 'F21', 'F22',\n",
    "'F23', 'F24', 'F25', 'F26', 'F27', 'F28', 'F29', 'F30', 'F31', 'F32', 'F33',\n",
    "'F34', 'F35', 'F36', 'F37', 'F38', 'F39', 'F40', 'F41', 'F42', 'F43', 'F44',\n",
    "'F45', 'F46', 'F47', 'F48', 'F49', 'F50', 'F51', 'F52', 'F53', 'F54', 'F55',\n",
    "'F56', 'F57', 'F58', 'F59', 'F60', 'F61', 'F62', 'F63', 'F64', 'F65', 'F66',\n",
    "'F67', 'F68', 'F69', 'F70', 'F71', 'F72', 'F73', 'F74', 'F75', 'F76', 'F77',\n",
    "'F78', 'F79', 'F80', 'F81', 'F82', 'F83', 'F84', 'F85', 'F86', 'F87', 'F88',\n",
    "'F89', 'F90', 'F91', 'F92', 'F93', 'F94', 'F95', 'F96', 'F97', 'F98', 'F99',\n",
    "'F100', 'F101', 'F102', 'F103', 'F104', 'F105', 'F106', 'F107', 'F108', 'F109',\n",
    "'F110', 'F111', 'F112', 'F113', 'F114', 'F115', 'F116', 'F117', 'F118', 'F119',\n",
    "'F120', 'F121', 'F122', 'F123', 'F124', 'F125', 'F126', 'F127', 'F128', 'F129',\n",
    "'F130', 'F131', 'F132', 'F133', 'F134', 'F135', 'F136', 'F137', 'F138', 'F139',\n",
    "'F140', 'F141', 'F142', 'F143', 'F144', 'F145', 'F146', 'F147', 'F148', 'F149',\n",
    "'F150', 'F151', 'F152', 'F153', 'F154', 'F155', 'F156', 'F157', 'F158', 'F159',\n",
    "'F160', 'F161', 'F162', 'F163', 'F164', 'F165', 'F166', 'F167', 'F168', 'F169',\n",
    "'F170', 'F171', 'F172', 'F173', 'F174', 'F175', 'F176', 'F177', 'F178', 'F179',\n",
    "'F180', 'F181', 'F182', 'F183', 'F184', 'F185', 'F186', 'F187', 'F188', 'F189',\n",
    "'F190', 'F191', 'F192', 'F193', 'F194', 'F195', 'F196', 'F197', 'F198', 'F199',\n",
    "'F200', 'F201', 'F202', 'F203', 'F204', 'F205', 'F206', 'F207', 'F208', 'F209',\n",
    "'F210', 'F211', 'F212', 'F213', 'F214', 'F215', 'F216', 'F217', 'F218', 'F219',\n",
    "'F220', 'F221', 'F222', 'F223', 'F224', 'F225', 'F226', 'F227', 'F228', 'F229',\n",
    "'F230', 'F231', 'F232', 'F233', 'F234', 'F235', 'F236', 'F237', 'F238', 'F239',\n",
    "'F240', 'F241', 'F242', 'F243', 'F244', 'F245', 'F246', 'F247', 'F248', 'F249',\n",
    "'F250', 'F251', 'F252', 'F253', 'F254', 'F255', 'F256', 'F257', 'F258', 'F259',\n",
    "'F260', 'F261', 'F262', 'F263', 'F264', 'F265', 'F266', 'F267', 'F268', 'F269',\n",
    "'F270', 'F271', 'F272', 'F273', 'F274', 'F275', 'F276', 'F277', 'F278', 'F279',\n",
    "'F280', 'F281', 'F282', 'F283', 'F284', 'F285', 'F286', 'F287', 'F288', 'F289',\n",
    "'F290', 'F291', 'F292', 'F293', 'F294', 'F295', 'F296', 'F297', 'F298', 'F299',\n",
    "'F300', 'Kelas']\n",
    "#headerList2 = ['PSTV01', 'PSTV02',\n",
    "'PSTV15','FKP02','FKP03','FKP04','FKP05','FKP06','FKP07','FKP08','FKP09','FKP10',\n",
    "'FKP11','FKP12','FKP14','FKP14A','FKP15','FKP15A','FKP16','FKP17','FKP18','FKP19\n",
    "','FKP20','FKP21','FKP22']\n",
    "# converting data frame to csv\n",
    "df_bonus.to_csv(\"train_data.csv\", header=headerList, index=False)\n",
    "#df_test.to_csv(\"test_fktp_header.csv\", header=headerList2, index=False)\n",
    "# display modified csv file\n",
    "#file2 = pd.read_csv(\"train_fktp_header.csv\")\n",
    "#filetest = pd.read_csv(\"test_fktp_header.csv\")\n",
    "print('\\nModified file save')\n",
    "[ ]\n",
    "print(\" \\nJumlah total missing value data pada masing-masing kolom :\n",
    "\\n\\n\",file2.isnull().sum())\n",
    "print(\" \\nJumlah total missing value data pada masing-masing kolom File:\n",
    "\\n\\n\",filetest.isnull().sum())\n",
    "[ ]\n",
    "Xawal=file2.iloc[:,:-1]# attributes to\n",
    "determine dependent variable / Class\n",
    "Y=file2.iloc[:,-1]# dependent variable /\n",
    "Class\n",
    "print('x:',Xawal)\n",
    "print('y',Y)\n",
    "[ ]\n",
    "# Menggunakan Filters AddClutering Classifier Random Forest\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "import seaborn as sns\n",
    "# Membuat data contoh\n",
    "X, y = make_blobs(n_samples=300, centers=4, random_state=42)\n",
    "# Melakukan clustering dengan KMeans\n",
    "kmeans = KMeans(n_clusters=4, random_state=42)\n",
    "kmeans_labels = kmeans.fit_predict(X)\n",
    "# Menambahkan label clustering ke data\n",
    "X_clustered = np.column_stack((X, kmeans_labels))\n",
    "# Memisahkan data menjadi data pelatihan dan pengujian\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_clustered, y, test_size=0.2,\n",
    "random_state=42)\n",
    "# Membuat dan melatih classifier menggunakan Random Forest\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train, Y_train)\n",
    "# Memprediksi label menggunakan classifier\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "# Menghitung akurasi\n",
    "accuracy = accuracy_score(Y_test, y_pred)\n",
    "sns.heatmap(cm,annot=True)\n",
    "print(f'Akurasi yang dihasilkan pada proses pengujian adalah {accuracy *\n",
    "100:.2f}%\\n')\n",
    "print(\"Dan berikut merupakan hasil evaluasi secara keseluruhan:\\n\\n\",\n",
    "classification_report(Y_test, y_pred))s"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
